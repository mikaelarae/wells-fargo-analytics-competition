{"name":"Wells Fargo Analytics Competition","tagline":"Wells Fargo Analytics Competition","body":"No one wants to feel stranded when traveling. Unfortunately, through analysis of social media posts referencing banks, there is a definite need for change in the way banks operate outside of their region. Our approach was to examine the data and isolate terms which could be used to distinguish the general feelings towards the each individual banks’ foreign/abroad transactions. Our methodology was to isolate each bank and then run a sentiment analysis for positive and negative words (lexicons) within posts containing the words foreign and abroad. We ran a sentiment analysis and interpreted the graphs and ratios. Below is a visual representation of our analytic process flow. \r\n\r\nOur code:\r\nCleaning up the data:\r\nLoading R:\r\n```R \r\ndf = read.table('Dataset.txt',sep=\"|\",header=T)\r\ndf$FullText = as.character(df$FullText)\r\n# Grab just the texts, so you can load them in the Corpus\r\ndf.texts = as.data.frame(df[,ncol(df)])\r\ncolnames(df.texts) = 'FullText'\r\n# Remove non-ascii characters\r\ndf.texts.clean = as.data.frame(iconv(df.texts$FullText, \"latin1\", \"ASCII\", sub=\"\"))\r\ncolnames(df.texts.clean) = 'FullText'\r\ndf$FullText = df.texts.clean$FullText\r\n# If you want to test on just 1000 records using df.1000 created below\r\nidx.1000 = sample(1:nrow(df),1000)\r\ndf.1000 = df[idx.1000,]\r\n# Load using the tm library\r\nlibrary(tm) \r\ndocs <- Corpus(DataframeSource(df.texts.clean))\r\n# Strip extra whitespace\r\ndocs <- tm_map(docs, stripWhitespace)\r\nbankA.idx = which(sapply(df$FullText,function(x) grepl(\"BankA\",x)))\r\nbankB.idx = which(sapply(df$FullText,function(x) grepl(\"BankB\",x)))\r\nbankC.idx = which(sapply(df$FullText,function(x) grepl(\"BankC\",x)))\r\nbankD.idx = which(sapply(df$FullText,function(x) grepl(\"BankD\",x)))\r\ndf.banka=df[bankA.idx,]\r\ndf.banka\r\nabroad.idx=which(sapply(df.banka$FullText,function(x) grepl(\"abroad\",x)))\r\nabroad.idx\r\nforeign.idx=which(sapply(df.banka$FullText,function(x) grepl(\"foreign\",x)))\r\nforeign.idx\r\ndf.final1=df.banka[abroad.idx,]\r\ndf.final2=df.banka[foreign.idx,]\r\ndf.final1\r\ndf.final2\r\ntotal_bankA <- rbind(df.final1,df.final2)\r\ndf.bankb=df[bankB.idx,]\r\ndf.bankb\r\nabroad.idx=which(sapply(df.bankb$FullText,function(x) grepl(\"abroad\",x)))\r\nabroad.idx\r\nforeign.idx=which(sapply(df.bankb$FullText,function(x) grepl(\"foreign\",x)))\r\nforeign.idx\r\ndf.final1=df.bankb[abroad.idx,]\r\ndf.final2=df.bankb[foreign.idx,]\r\ndf.final1\r\ndf.final2\r\ntotal_bankC <- rbind(df.final1,df.final2)\r\ndf.bankc=df[bankC.idx,]\r\ndf.bankc\r\nabroad.idx=which(sapply(df.bankc$FullText,function(x) grepl(\"abroad\",x)))\r\nabroad.idx\r\nforeign.idx=which(sapply(df.bankc$FullText,function(x) grepl(\"foreign\",x)))\r\nforeign.idx\r\ndf.final1=df.bankc[abroad.idx,]\r\ndf.final2=df.bankc[foreign.idx,]\r\ndf.final1\r\ndf.final2\r\ntotal_bankC <- rbind(df.final1,df.final2)\r\ndf.bankd=df[bankD.idx,]\r\ndf.bankd\r\nabroad.idx=which(sapply(df.bankd$FullText,function(x) grepl(\"abroad\",x)))\r\nabroad.idx\r\nforeign.idx=which(sapply(df.bankd$FullText,function(x) grepl(\"foreign\",x)))\r\nforeign.idx\r\ndf.final1=df.bankd[abroad.idx,]\r\ndf.final2=df.bankd[foreign.idx,]\r\ndf.final1\r\ndf.final2\r\ntotal_bankD <- rbind(df.final1,df.final2)\r\n# This turns out to be too slow\r\n# Add the metadata\r\n# This takes a bit to run\r\n# You can add more here\r\n#‎for (i in 1:nrow(df)) {\r\n# meta(docs[[i]],\"MediaType\") = df$MediaType[i]\r\n# meta(docs[[i]],\"Year\") = df$Year[i]\r\n# if (grepl(\"BankA\",df$FullText[i])) {\r\n# meta(docs[[i]],\"BankA\") = T\r\n# } else {\r\n# meta(docs[[i]],\"BankA\") = F\r\n# }\r\n# if (grepl(\"BankB\",df$FullText[i])) {\r\n# meta(docs[[i]],\"BankB\") = T\r\n# } else {\r\n# meta(docs[[i]],\"BankB\") = F\r\n# }\r\n#}\r\n#‎bankA.idx <- meta(docs, \"BankA\") == T\r\nbankA.docs = docs[bankA.idx]\r\nbankB.docs = docs[bankB.idx]\r\nbankC.docs = docs[bankC.idx]\r\nbankD.docs = docs[bankD.idx]\r\nsummary(docs)\r\ndocs <- tm_map(docs, removePunctuation)\r\n\r\nWord Cloud:\r\nlibrary(wordcloud)   \r\nset.seed(142)   \r\ndark2 <- brewer.pal(6, \"Dark2\")   \r\nwordcloud(names(freq), freq, max.words=100, rot.per=0.2, colors=dark2)   \r\n\r\nRunning the sentiment analysis:\r\n#-------Sentiment analysis Bank A-------\r\npos <- scan('positive-words.txt',what='character',comment.char=';')\r\nneg <- scan('negative-words.txt',what='character',comment.char=';')\r\nscore.sentiment = function(sentences, pos.words, neg.words, .progress='none')\r\n{\r\nrequire(plyr)\r\nrequire(stringr)\r\n# we got a vector of sentences. plyr will handle a list\r\n# or a vector as an \"l\" for us\r\n# we want a simple array (\"a\") of scores back, so we use \r\n# \"l\" + \"a\" + \"ply\" = \"laply\":\r\nscores = laply(sentences, function(sentence, pos.words, neg.words) {\r\n# clean up sentences with R's regex-driven global substitute, gsub():\r\nsentence = gsub('[[:punct:]]', '', sentence)\r\nsentence = gsub('[[:cntrl:]]', '', sentence)\r\nsentence = gsub('\\\\d+', '', sentence)\r\n# and convert to lower case:\r\nsentence = tolower(sentence)\r\n# split into words. str_split is in the stringr package\r\nword.list = str_split(sentence, '\\\\s+')\r\n# sometimes a list() is one level of hierarchy too much\r\nwords = unlist(word.list)\r\n# compare our words to the dictionaries of positive & negative terms\r\npos.matches = match(words, pos.words)\r\nneg.matches = match(words, neg.words)\r\n# match() returns the position of the matched term or NA\r\n# we just want a TRUE/FALSE:\r\npos.matches = !is.na(pos.matches)\r\nneg.matches = !is.na(neg.matches)\r\n# and conveniently enough, TRUE/FALSE will be treated as 1/0 by sum():\r\nscore = sum(pos.matches) - sum(neg.matches)\r\nreturn(score)\r\n}, pos.words, neg.words, .progress=.progress )\r\nscores.df = data.frame(score=scores, text=sentences)\r\nreturn(scores.df)\r\n}\r\ntotal.sentiment = total_bankA\r\nscores = score.sentiment(as.character(total.sentiment$FullText), pos, neg, .progress='text')\r\nscores$very.pos = as.numeric(scores$score >= 1)\r\nscores$very.neg = as.numeric(scores$score <= -1)\r\n# how many very positives and very negatives\r\nnumpos = sum(scores$very.pos)\r\nnumneg = sum(scores$very.neg)\r\n# global score\r\nglobal_score = round( 100 * numpos / (numpos + numneg) )\r\nscores$mediatype = total.sentiment$MediaType\r\n# colors\r\ncols = c(\"#‎7CAE00\", \"#‎00BFC4\")\r\nnames(cols) = c(\"twitter\", \"facebook\")\r\n# boxplot\r\nlibrary(ggplot2)\r\nggplot(scores, aes(x=mediatype, y=score, group=mediatype)) +\r\ngeom_boxplot(aes(fill=mediatype)) +\r\nscale_fill_manual(values=cols) +\r\ngeom_jitter(colour=\"gray40\",position=position_jitter(width=0.2), alpha=0.3) +\r\nlabs(title = \"Media Type's Sentiment Scores\") + \r\nxlab('Media Type') + ylab('Sentiment Score')\r\n# barplot of average score\r\nmeanscore = tapply(scores$score, scores$mediatype, mean)\r\ndf.plot = data.frame(mediatype=names(meanscore), meanscore=meanscore)\r\ndf.plot$mediatypes <- reorder(df.plot$mediatype, df.plot$meanscore)\r\nggplot(df.plot, aes(x = factor(mediatypes), y = meanscore, fill=mediatypes)) +\r\ngeom_bar(stat=\"identity\") +\r\nscale_fill_manual(values=cols[order(df.plot$meanscore)]) +\r\nlabs(title = \"Average Sentiment Score\") + \r\nxlab('Media Type') + ylab('Average Score')\r\n# barplot of average very positive\r\nmediatype_pos = ddply(scores, .(mediatype), summarise, mean_pos=mean(very.pos))\r\nmediatype_pos$mediatypes <- reorder(mediatype_pos$mediatype, mediatype_pos$mean_pos)\r\nggplot(mediatype_pos, aes(x = factor(mediatypes), y = mean_pos, fill=mediatypes)) +\r\ngeom_bar(stat=\"identity\") +\r\nscale_fill_manual(values=cols[order(df.plot$meanscore)]) +\r\nlabs(title = \"Average Fraction Very Positive Sentiment Score (Bank A)\") + \r\nxlab('Media Type') + ylab('Average Score')\r\nmediatype_neg = ddply(scores, .(mediatype), summarise, mean_neg=mean(very.neg))\r\nmediatype_neg$mediatypes <- reorder(mediatype_pos$mediatype, mediatype_neg$mean_neg)\r\nggplot(mediatype_neg, aes(x = factor(mediatypes), y = mean_neg, fill=mediatypes)) +\r\ngeom_bar(stat=\"identity\") +\r\nscale_fill_manual(values=cols[order(df.plot$meanscore)]) +\r\nlabs(title = \"Average Fraction Very Negative Sentiment Score (Bank A)\") + \r\nxlab('Media Type') + ylab('Average Score')\r\n#-------Sentiment analysis Bank B-------\r\ntotal.sentiment = total_bankB\r\nscores = score.sentiment(as.character(total.sentiment$FullText), pos, neg, .progress='text')\r\nscores$very.pos = as.numeric(scores$score >= 1)\r\nscores$very.neg = as.numeric(scores$score <= -1)\r\n# how many very positives and very negatives\r\nnumpos = sum(scores$very.pos)\r\nnumneg = sum(scores$very.neg)\r\n# global score\r\nglobal_score = round( 100 * numpos / (numpos + numneg) )\r\nscores$mediatype = total.sentiment$MediaType\r\n# colors\r\ncols = c(\"#7CAE00\", \"#00BFC4\")\r\nnames(cols) = c(\"twitter\", \"facebook\")\r\n# boxplot\r\nlibrary(ggplot2)\r\nggplot(scores, aes(x=mediatype, y=score, group=mediatype)) +\r\ngeom_boxplot(aes(fill=mediatype)) +\r\nscale_fill_manual(values=cols) +\r\ngeom_jitter(colour=\"gray40\",position=position_jitter(width=0.2), alpha=0.3) +\r\nlabs(title = \"Media Type's Sentiment Scores\") + \r\nxlab('Media Type') + ylab('Sentiment Score')\r\n# barplot of average score\r\nmeanscore = tapply(scores$score, scores$mediatype, mean)\r\ndf.plot = data.frame(mediatype=names(meanscore), meanscore=meanscore)\r\ndf.plot$mediatypes <- reorder(df.plot$mediatype, df.plot$meanscore)\r\nggplot(df.plot, aes(x = factor(mediatypes), y = meanscore, fill=mediatypes)) +\r\ngeom_bar(stat=\"identity\") +\r\nscale_fill_manual(values=cols[order(df.plot$meanscore)]) +\r\nlabs(title = \"Average Sentiment Score\") + \r\nxlab('Media Type') + ylab('Average Score')\r\n# barplot of average very positive\r\nmediatype_pos = ddply(scores, .(mediatype), summarise, mean_pos=mean(very.pos))\r\nmediatype_pos$mediatypes <- reorder(mediatype_pos$mediatype, mediatype_pos$mean_pos)\r\nggplot(mediatype_pos, aes(x = factor(mediatypes), y = mean_pos, fill=mediatypes)) +\r\ngeom_bar(stat=\"identity\") +\r\nscale_fill_manual(values=cols[order(df.plot$meanscore)]) +\r\nlabs(title = \"Average Fraction Very Positive Sentiment Score (Bank B)\") + \r\nxlab('Media Type') + ylab('Average Score')\r\nmediatype_neg = ddply(scores, .(mediatype), summarise, mean_neg=mean(very.neg))\r\nmediatype_neg$mediatypes <- reorder(mediatype_pos$mediatype, mediatype_neg$mean_neg)\r\nggplot(mediatype_neg, aes(x = factor(mediatypes), y = mean_neg, fill=mediatypes)) +\r\ngeom_bar(stat=\"identity\") +\r\nscale_fill_manual(values=cols[order(df.plot$meanscore)]) +\r\nlabs(title = \"Average Fraction Very Negative Sentiment Score (Bank B)\") + \r\nxlab('Media Type') + ylab('Average Score')\r\n#-------Sentiment analysis Bank C-------\r\ntotal.sentiment = total_bankC\r\nscores = score.sentiment(as.character(total.sentiment$FullText), pos, neg, .progress='text')\r\nscores$very.pos = as.numeric(scores$score >= 1)\r\nscores$very.neg = as.numeric(scores$score <= -1)\r\n# how many very positives and very negatives\r\nnumpos = sum(scores$very.pos)\r\nnumneg = sum(scores$very.neg)\r\n# global score\r\nglobal_score = round( 100 * numpos / (numpos + numneg) )\r\nscores$mediatype = total.sentiment$MediaType\r\n# colors\r\ncols = c(\"#7CAE00\", \"#00BFC4\")\r\nnames(cols) = c(\"twitter\", \"facebook\")\r\n# boxplot\r\nlibrary(ggplot2)\r\nggplot(scores, aes(x=mediatype, y=score, group=mediatype)) +\r\ngeom_boxplot(aes(fill=mediatype)) +\r\nscale_fill_manual(values=cols) +\r\ngeom_jitter(colour=\"gray40\",position=position_jitter(width=0.2), alpha=0.3) +\r\nlabs(title = \"Media Type's Sentiment Scores\") + \r\nxlab('Media Type') + ylab('Sentiment Score')\r\n# barplot of average score\r\nmeanscore = tapply(scores$score, scores$mediatype, mean)\r\ndf.plot = data.frame(mediatype=names(meanscore), meanscore=meanscore)\r\ndf.plot$mediatypes <- reorder(df.plot$mediatype, df.plot$meanscore)\r\nggplot(df.plot, aes(x = factor(mediatypes), y = meanscore, fill=mediatypes)) +\r\ngeom_bar(stat=\"identity\") +\r\nscale_fill_manual(values=cols[order(df.plot$meanscore)]) +\r\nlabs(title = \"Average Sentiment Score\") + \r\nxlab('Media Type') + ylab('Average Score')\r\n# barplot of average very positive\r\nmediatype_pos = ddply(scores, .(mediatype), summarise, mean_pos=mean(very.pos))\r\nmediatype_pos$mediatypes <- reorder(mediatype_pos$mediatype, mediatype_pos$mean_pos)\r\nggplot(mediatype_pos, aes(x = factor(mediatypes), y = mean_pos, fill=mediatypes)) +\r\ngeom_bar(stat=\"identity\") +\r\nscale_fill_manual(values=cols[order(df.plot$meanscore)]) +\r\nlabs(title = \"Average Fraction Very Positive Sentiment Score (Bank C)\") + \r\nxlab('Media Type') + ylab('Average Score')\r\nmediatype_neg = ddply(scores, .(mediatype), summarise, mean_neg=mean(very.neg))\r\nmediatype_neg$mediatypes <- reorder(mediatype_pos$mediatype, mediatype_neg$mean_neg)\r\nggplot(mediatype_neg, aes(x = factor(mediatypes), y = mean_neg, fill=mediatypes)) +\r\ngeom_bar(stat=\"identity\") +\r\nscale_fill_manual(values=cols[order(df.plot$meanscore)]) +\r\nlabs(title = \"Average Fraction Very Negative Sentiment Score (Bank C)\") +\r\nxlab('Media Type') + ylab('Average Score')\r\n#-------Sentiment analysis Bank D-------\r\ntotal.sentiment = total_bankD\r\nscores = score.sentiment(as.character(total.sentiment$FullText), pos, neg, .progress='text')\r\nscores$very.pos = as.numeric(scores$score >= 1)\r\nscores$very.neg = as.numeric(scores$score <= -1)\r\n# how many very positives and very negatives\r\nnumpos = sum(scores$very.pos)\r\nnumneg = sum(scores$very.neg)\r\n# global score\r\nglobal_score = round( 100 * numpos / (numpos + numneg) )\r\n# colors\r\ncols = c(\"#7CAE00\", \"#00BFC4\")\r\nnames(cols) = c(\"twitter\", \"facebook\")\r\n# boxplot\r\nlibrary(ggplot2)\r\nggplot(scores, aes(x=mediatype, y=score, group=mediatype)) +\r\ngeom_boxplot(aes(fill=mediatype)) +\r\nscale_fill_manual(values=cols) +\r\ngeom_jitter(colour=\"gray40\",position=position_jitter(width=0.2), alpha=0.3) +\r\nlabs(title = \"Media Type's Sentiment Scores\") + \r\nxlab('Media Type') + ylab('Sentiment Score')\r\n# barplot of average score\r\nmeanscore = tapply(scores$score, scores$mediatype, mean)\r\ndf.plot = data.frame(mediatype=names(meanscore), meanscore=meanscore)\r\ndf.plot$mediatypes <- reorder(df.plot$mediatype, df.plot$meanscore)\r\nggplot(df.plot, aes(x = factor(mediatypes), y = meanscore, fill=mediatypes)) +\r\ngeom_bar(stat=\"identity\") +\r\nscale_fill_manual(values=cols[order(df.plot$meanscore)]) +\r\nlabs(title = \"Average Sentiment Score\") + \r\nxlab('Media Type') + ylab('Average Score')\r\n# barplot of average very positive\r\nmediatype_pos = ddply(scores, .(mediatype), summarise, mean_pos=mean(very.pos))\r\nmediatype_pos$mediatypes <- reorder(mediatype_pos$mediatype, mediatype_pos$mean_pos)\r\nggplot(mediatype_pos, aes(x = factor(mediatypes), y = mean_pos, fill=mediatypes)) +\r\ngeom_bar(stat=\"identity\") +\r\nscale_fill_manual(values=cols[order(df.plot$meanscore)]) +\r\nlabs(title = \"Average Fraction Very Positive Sentiment Score (Bank D)\") + \r\nxlab('Media Type') + ylab('Average > Score')\r\nmediatype_neg = ddply(scores, .(mediatype), summarise, mean_neg=mean(very.neg))\r\nmediatype_neg$mediatypes <- reorder(mediatype_pos$mediatype, mediatype_neg$mean_neg)\r\nggplot(mediatype_neg, aes(x = factor(mediatypes), y = mean_neg, fill=mediatypes)) +\r\ngeom_bar(stat=\"identity\") +\r\nscale_fill_manual(values=cols[order(df.plot$meanscore)]) +\r\nlabs(title = \"Average Fraction Very Negative Sentiment Score (Bank D)\") +\r\nxlab('Media Type') + ylab('Average Score')\r\ndocs<- tm_map(docs, removeWords, stopwords(\"twithndl\", \"internet\", \"nameresp\", \"rettwit\" ))\r\nlibrary(wordcloud) \r\nset.seed(142) \r\ndark2 <- brewer.pal(6, \"Dark2\") \r\nwordcloud(names(freq), freq, max.words=75, rot.per=0.3, colors=dark2)\r\n\r\n\r\n```\r\nOur code reflects our analytical process flow in that we extracted the raw data and used r to clean the data. We removed punctuation, non-important words, numbers, etc. We also divided the data into bank specific data frames. We then ran sentiment analyses for negative and positive feelings towards foreign affairs and abroad transactions for each bank. We analyzed our data and tried to make inferences based on the negative to positive ratios. \r\nWe noticed many topics; some keywords we found were withdrawn, overdrawn, customer service, and foreign/abroad transactions. We focused on the topics of foreign affairs and abroad transactions. The substances were determined for each bank based on their negative to positive ratios. Below are our graphs for the positive and negative sentiment analyses for each bank.\r\n\r\n\r\nBank A had an average of 0.32:0.28 (1.14) (twitter) and 0.38:0.32 (1.19)(Facebook) (Negative: Positive)\r\nBank B had an average 0.24:0.27 (0.89) (twitter) and 0.38:0.21 (1.81) (Facebook) (Negative: Positive)\r\nBank C had an average ratio (Negative: Positive) of 0.46:0.16 (2.88) (twitter) and 0.34:0.24 (1.42) (Facebook)\r\nBank D had an average ratio (Negative: Positive) of 0.16:0.07 (2.29) (twitter) and 0.46:0.26 (1.77) (Facebook)\r\n##Conclusion\r\n\r\nAfter analyzing the ratios from our sentiment we found that for the topics of foreign and abroad Bank C had the most negative posts with Bank D as a close second. We further investigated the data to determine the substances and found that customers were unhappy with bank cards not working abroad. We also found that many customers felt negatively towards foreign exchange fees, some claiming that Bank D and Bank C must be “rigging” the fee rates. Bank A and Bank B had fairly even negative and positive ratios, additionally they had the least percentage of negative posts of the 4 banks when considering the topics of foreign and abroad transactions. We don’t believe we can necessarily draw any definite inferences from the sentiment analysis as there is no clear evidence that the banks did in fact rig the foreign exchange fee rates, but we can see that it is an important factor that customers are associating with these banks. The use of cards abroad is also an important factor to these customers, and can be an issue that these banks may find worthwhile investigating further. \r\n\r\n![Word Cloud] (http://i.imgur.com/SLmaIkn.png)\r\n!![Bank A] (http://cdn.makeagif.com/media/12-03-2015/JFjpzl.gif) \r\n!![Bank B] (http://cdn.makeagif.com/media/12-12-2015/Zu8pAf.gif)\r\n!![Bank C] (http://cdn.makeagif.com/media/12-12-2015/_nJSPm.gif)\r\n!![Bank D] (http://cdn.makeagif.com/media/12-12-2015/MIT06u.gif)\r\n\r\n#About the Creator\r\nMikaela Merlin-Pfau is a junior (as of dec 2015) at College of Charleston. She is a sociology major and data science minor with hopes of attending MUSC's Master of Health Analytics program after she graduates. She lives at her home in Summerville with her husband of 2 years (newlyweds!), two dog babies, and her hedgehog - Willow. \r\n![] (https://scontent-atl3-1.xx.fbcdn.net/hphotos-xfa1/v/t1.0-9/1001511_10151775408386554_1494859151_n.jpg?oh=c6adc048e87f7a6918b35406f12cbe54&oe=5713C1AC)\r\n@tiffanirgriffith @koatliky","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}